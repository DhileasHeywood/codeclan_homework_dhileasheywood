---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(GGally)
```


```{r}
avocado <- read_csv("data/avocado.csv") %>% 
  janitor::clean_names()
```

```{r}
glimpse(avocado)
```

```{r}
unique(clean_avocado$region)
```

```{r}

clean_avocado <- avocado %>% 
  filter(region != c("Midsouth", "Northeast", "SouthCentral", "Southeast", "TotalUS", "West")) %>% 
  mutate_if(is_character, as_factor) %>% 
  mutate(year = as_factor(year)) %>% 
  select(-x1, -date) %>%
  na.omit()

```

splitting the data intp a training and testing set. 

```{r}
n_avocado <- nrow(clean_avocado)

test_index <- sample(1:n_avocado, size = n_avocado * 0.2)

avocado_test <- slice(clean_avocado, test_index)

avocado_train <- slice(clean_avocado, -test_index)
```


```{r}
avocado_test %>% 
  janitor::tabyl(type)
```

```{r}
avocado_train %>% 
  janitor::tabyl(type)
```

```{r fig.height=30, fig.width=40}
avocado_fit <- rpart(type ~ ., 
                     data = avocado_train,
                     method = "class")

rpart.plot(avocado_fit, yesno = 2)
```

```{r}
rpart.rules(avocado_fit, cover = TRUE)
```






# Clustering!

```{r}
arrests <- USArrests %>% 
  janitor::clean_names() %>%
  rownames_to_column("state") 
```

```{r}
arrests %>% 
  column_to_rownames("state") %>% 
  ggpairs()
```

```{r}
arrests_scale <- arrests %>% 
  mutate_if(is.numeric, scale) %>% 
  column_to_rownames("state")

plot(arrests_scale)
  
```
```{r}
library(factoextra)
library(broom)
```


Performing elbow method analysis to assist choosing number of clusters. 

```{r}
max_k <- 20
k_clusters <- tibble(k = 2:max_k) %>%
  mutate(
    kclust = map(k, ~ kmeans(arrests_scale, .x, nstart = 25)), 
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, arrests_scale)
  )
k_clusters

clusterings <- k_clusters %>%
  unnest(glanced)
clusterings

ggplot(clusterings, aes(x=k, y=tot.withinss)) +
  geom_point() +
    geom_line() +
    scale_x_continuous(breaks = seq(1, 20, by = 1))
```
This would suggest that there should be 4 clusters. 




performing silhouette coefficient analysis to assist choosing number of clusters. 
```{r}
fviz_nbclust(arrests_scale, kmeans, method = "silhouette")
```
This suggests that there should be 2 clusters. 

perfoming gap statistic analysis to assist choosing number of clusters. 
```{r}
fviz_nbclust(arrests_scale, kmeans, method = "gap_stat")
```
this suggests that there should be 2 clusters. 


```{r}
kmeans_arrests <- kmeans(arrests_scale, 2, nstart = 25)

fviz_cluster(kmeans_arrests, arrests_scale, frame.type = "norm")

```

```{r}
clusterings %>% 
  unnest(cols = c(augmented)) %>% 
  filter(k == 2) %>% 
  group_by(.cluster) %>% 
  summarise(mean(rape), mean(murder), mean(assault), mean(urban_pop), n())
```

